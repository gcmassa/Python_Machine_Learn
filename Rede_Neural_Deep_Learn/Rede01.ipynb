{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c6b3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\"if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c01763e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, validador, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
    "            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if (etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "    print(\"Total de imgens testadas = \", conta_todas)\n",
    "    print(\"\\nPrecisão do modelo - {}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdd388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a politica de atualizacao dos pesos e da baias\n",
    "    inicio = time() # timer para sabermos quanto tempo levou o treinamento\n",
    "\n",
    "    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10 # numero de epochs que o algoritmo rodara OBS: ideal o valor ser no minimo 100 para um bom treinamento\n",
    "    modelo.train() # ativando o modelo de treinamento\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens \"vetores\" de 28*28 para vetores de 784\n",
    "            otimizador.zero_grad() # zerando os gadientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward() # propagando a partir da perda instantânea\n",
    "\n",
    "            otimizador.step() # atualizando os pesos e as baias do modelo\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda: {}\".format(epoch + 1, perda_acumulada / len(trainloader)))\n",
    "    print(\"\\nTempo de Treino (em minutos) = \", (time() - inicio) / 60) # tempo total de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b2e6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entradam 784 neuronios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neuronios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neuronios que se ligam a 10\n",
    "        # para a camada de saida não é necessario definir nada pois só preciso pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada pra camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para camada interna 2\n",
    "        X = self.linear3(X) # função de ativação da camada interna 2 para camada de saída, neste caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc3b8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # para mostrar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # para verificar o tamanho do tensor da etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e16f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x239b8a8f110>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader) #carraga da iteração do dataset\n",
    "imagens, etiquetas = next(dataiter) #pega a próxima imagem e etiqueta do dataset\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r') #mostra a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c25bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # definindo a conversão  da imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MINST_data/', download=True, train=True, transform=transform)#Carraga a parte do treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)#Cria o buffer para pegar os dados do dataset\n",
    "\n",
    "valset = datasets.MNIST('./MINST_data/', download=True, train=False, transform=transform)#Carrega a parte da validação do dataset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)#Cria o buffer para pegar os dados do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc110823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
