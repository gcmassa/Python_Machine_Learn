{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7c6b3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\"if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01763e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, validador, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
    "            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if (etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "    print(\"Total de imgens testadas = \", conta_todas)\n",
    "    print(\"\\nPrecisão do modelo - {}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bdd388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a politica de atualizacao dos pesos e da baias\n",
    "    inicio = time() # timer para sabermos quanto tempo levou o treinamento\n",
    "\n",
    "    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10 # numero de epochs que o algoritmo rodara OBS: ideal o valor ser no minimo 100 para um bom treinamento\n",
    "    modelo.train() # ativando o modelo de treinamento\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens \"vetores\" de 28*28 para vetores de 784\n",
    "            otimizador.zero_grad() # zerando os gadientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward() # propagando a partir da perda instantânea\n",
    "\n",
    "            otimizador.step() # atualizando os pesos e as baias do modelo\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda: {}\".format(epoch + 1, perda_acumulada / len(trainloader)))\n",
    "    print(\"\\nTempo de Treino (em minutos) = \", (time() - inicio) / 60) # tempo total de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2e6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entradam 784 neuronios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neuronios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neuronios que se ligam a 10\n",
    "        # para a camada de saida não é necessario definir nada pois só preciso pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada pra camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para camada interna 2\n",
    "        X = self.linear3(X) # função de ativação da camada interna 2 para camada de saída, neste caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc3b8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # para mostrar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # para verificar o tamanho do tensor da etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e16f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a7f81bd450>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader) #carraga da iteração do dataset\n",
    "imagens, etiquetas = next(dataiter) #pega a próxima imagem e etiqueta do dataset\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r') #mostra a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c25bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # definindo a conversão  da imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MINST_data/', download=True, train=True, transform=transform)#Carraga a parte do treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)#Cria o buffer para pegar os dados do dataset\n",
    "\n",
    "valset = datasets.MNIST('./MINST_data/', download=True, train=False, transform=transform)#Carrega a parte da validação do dataset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)#Cria o buffer para pegar os dados do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc110823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
