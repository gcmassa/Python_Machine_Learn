{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7c6b3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modelo(\n",
       "  (linear1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (linear3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = Modelo()\n",
    "device = torch.device(\"cuda\"if torch.cuda.is_available() else \"cpu\")\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c01763e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validacao(modelo, validador, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "    for imagens, etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "            # desativar o autograd para acelerar a validação. Grafos computacionais dinâmicos tem um custo de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # output do modelo em escala logarítmica\n",
    "            ps = torch.exp(logps) # converte output para escala normal(lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # converte o tensor em um número, no caso, o número que o modelo previu\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            if (etiqueta_certa == etiqueta_pred): # compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "    print(\"Total de imgens testadas = \", conta_todas)\n",
    "    print(\"\\nPrecisão do modelo - {}%\".format(conta_corretas*100/conta_todas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdd388e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treino(modelo, trainloader, device):\n",
    "\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5) # define a politica de atualizacao dos pesos e da baias\n",
    "    inicio = time() # timer para sabermos quanto tempo levou o treinamento\n",
    "\n",
    "    criterio = nn.NLLLoss() # definindo o criterio para calcular a perda\n",
    "    EPOCHS = 10 # numero de epochs que o algoritmo rodara OBS: ideal o valor ser no minimo 100 para um bom treinamento\n",
    "    modelo.train() # ativando o modelo de treinamento\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicialização da perda acumulada em questão\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "\n",
    "            imagens = imagens.view(imagens.shape[0], -1) # convertendo as imagens \"vetores\" de 28*28 para vetores de 784\n",
    "            otimizador.zero_grad() # zerando os gadientes por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) # colocando os dados no modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # calculando a perda da epoch em questão\n",
    "\n",
    "            perda_instantanea.backward() # propagando a partir da perda instantânea\n",
    "\n",
    "            otimizador.step() # atualizando os pesos e as baias do modelo\n",
    "\n",
    "            perda_acumulada += perda_instantanea.item() # atualização da perda acumulada\n",
    "        else:\n",
    "            print(\"Epoch {} - Perda: {}\".format(epoch + 1, perda_acumulada / len(trainloader)))\n",
    "    print(\"\\nTempo de Treino (em minutos) = \", (time() - inicio) / 60) # tempo total de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b2e6ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()\n",
    "        self.linear1 = nn.Linear(28*28, 128) # camada de entradam 784 neuronios que se ligam a 128\n",
    "        self.linear2 = nn.Linear(128, 64) # camada interna 1, 128 neuronios que se ligam a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # camada interna 2, 64 neuronios que se ligam a 10\n",
    "        # para a camada de saida não é necessario definir nada pois só preciso pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) # função de ativação da camada de entrada pra camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # função de ativação da camada interna 1 para camada interna 2\n",
    "        X = self.linear3(X) # função de ativação da camada interna 2 para camada de saída, neste caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc3b8f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "print(imagens[0].shape) # para mostrar as dimensões do tensor de cada imagem\n",
    "print(etiquetas[0].shape) # para verificar o tamanho do tensor da etiqueta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e16f462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a7f670a490>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader) #carraga da iteração do dataset\n",
    "imagens, etiquetas = next(dataiter) #pega a próxima imagem e etiqueta do dataset\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r') #mostra a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c25bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.ToTensor() # definindo a conversão  da imagem para tensor\n",
    "\n",
    "trainset = datasets.MNIST('./MINST_data/', download=True, train=True, transform=transform)#Carraga a parte do treino do dataset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)#Cria o buffer para pegar os dados do dataset\n",
    "\n",
    "valset = datasets.MNIST('./MINST_data/', download=True, train=False, transform=transform)#Carrega a parte da validação do dataset\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)#Cria o buffer para pegar os dados do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fc110823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
