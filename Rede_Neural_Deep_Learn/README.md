## ImplementaÃ§Ã£o de uma Rede DEEP LEARN para reconhecimento de DÃ­gitos
## ğŸ§  1. ImportaÃ§Ã£o de Bibliotecas

Essas bibliotecas sÃ£o essenciais para manipulaÃ§Ã£o de dados, construÃ§Ã£o da rede neural e visualizaÃ§Ã£o:

- `numpy`: operaÃ§Ãµes matemÃ¡ticas e manipulaÃ§Ã£o de arrays.
- `torch`: biblioteca principal do PyTorch.
- `torch.nn.functional`: funÃ§Ãµes auxiliares para redes neurais.
- `torchvision`: acesso a datasets e transformaÃ§Ãµes de imagem.
- `matplotlib.pyplot`: visualizaÃ§Ã£o de imagens.
- `time`: mediÃ§Ã£o de tempo de execuÃ§Ã£o.
- `torch.nn`: construÃ§Ã£o de camadas da rede.
- `torch.optim`: algoritmos de otimizaÃ§Ã£o.

---

## ğŸ–¼ï¸ 2. PreparaÃ§Ã£o dos Dados

### ğŸ”„ TransformaÃ§Ã£o
```python
transform = transforms.ToTensor()
```
- Converte imagens PIL para tensores PyTorch.

### ğŸ“š Carregamento do Dataset MNIST
```python
trainset = datasets.MNIST(...)
valset = datasets.MNIST(...)
```
- `train=True`: dados de treino.
- `train=False`: dados de validaÃ§Ã£o.
- `download=True`: baixa o dataset se necessÃ¡rio.

### ğŸšš DataLoaders
```python
trainloader = torch.utils.data.DataLoader(...)
valloader = torch.utils.data.DataLoader(...)
```
- `batch_size=64`: processa 64 imagens por vez.
- `shuffle=True`: embaralha os dados para melhor generalizaÃ§Ã£o.

---

## ğŸ‘ï¸ 3. VisualizaÃ§Ã£o de Imagem

```python
dataiter = iter(trainloader)
imagens, etiquetas = next(dataiter)
plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')
```
- Exibe a primeira imagem do lote em escala de cinza.
- `squeeze()` remove dimensÃµes extras.

### ğŸ“ VerificaÃ§Ã£o de DimensÃµes
```python
print(imagens[0].shape)
print(etiquetas[0].shape)
```
- Confirma o formato dos tensores de imagem e etiqueta.

---

## ğŸ—ï¸ 4. DefiniÃ§Ã£o da Arquitetura da Rede Neural

### ğŸ”§ Classe Modelo
```python
class Modelo(nn.Module):
```
- Herda de `nn.Module`, estrutura base do PyTorch.

### ğŸ§© Camadas da Rede
```python
self.linear1 = nn.Linear(28*28, 128)
self.linear2 = nn.Linear(128, 64)
self.linear3 = nn.Linear(64, 10)
```
- Rede totalmente conectada (fully connected).
- Entrada: 784 neurÃ´nios (28x28 pixels).
- SaÃ­da: 10 neurÃ´nios (dÃ­gitos de 0 a 9).

### ğŸ” Forward Pass
```python
def forward(self, X):
    ...
    return F.log_softmax(X, dim=1)
```
- Aplica ReLU nas camadas ocultas.
- `log_softmax`: prepara saÃ­da para cÃ¡lculo da perda com `NLLLoss`.

---

## ğŸ‹ï¸ 5. FunÃ§Ã£o de Treinamento

### âš™ï¸ ConfiguraÃ§Ãµes Iniciais
```python
otimizador = optim.SGD(...)
criterio = nn.NLLLoss()
EPOCHS = 10
```
- `SGD`: gradiente descendente estocÃ¡stico.
- `momentum=0.5`: acelera a convergÃªncia.
- `NLLLoss`: perda logarÃ­tmica negativa.

### ğŸ”„ Loop de Treinamento
```python
for epoch in range(EPOCHS):
    for imagens, etiquetas in trainloader:
        ...
```
- Converte imagens para vetores de 784 elementos.
- Zera gradientes, calcula perda, faz backpropagation e atualiza pesos.

### ğŸ“Š Monitoramento
```python
print("Epoch {} - Perda: {}".format(...))
```
- Exibe perda mÃ©dia por Ã©poca.
- Mede tempo total de treinamento.

---

## âœ… 6. FunÃ§Ã£o de ValidaÃ§Ã£o

### ğŸ” AvaliaÃ§Ã£o do Modelo
```python
with torch.no_grad():
    logps = modelo(img.to(device))
```
- Desativa cÃ¡lculo de gradientes para acelerar validaÃ§Ã£o.

### ğŸ“ˆ CÃ¡lculo de PrecisÃ£o
```python
probab = list(ps.cpu().numpy()[0])
etiqueta_pred = probab.index(max(probab))
```
- Converte saÃ­da para probabilidades.
- Compara previsÃ£o com etiqueta real.

### ğŸ“‹ Resultado Final
```python
print("PrecisÃ£o do modelo - {}%".format(...))
```
- Exibe a acurÃ¡cia do modelo sobre o conjunto de validaÃ§Ã£o.

---

## ğŸ–¥ï¸ 7. ExecuÃ§Ã£o do Modelo

### ğŸš€ InicializaÃ§Ã£o
```python
modelo = Modelo()
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
modelo.to(device)
```
- Usa GPU se disponÃ­vel.
- Move o modelo para o dispositivo apropriado.

